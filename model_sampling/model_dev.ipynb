{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sqlalchemy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.base.Connection at 0x1fa811bbbb0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CWD = os.getcwd()\n",
    "dataset_engine = sqlalchemy.create_engine(f\"sqlite:///{CWD}/modeling_dataset.db\")\n",
    "dataset_engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>tbl_name</th>\n",
       "      <th>rootpage</th>\n",
       "      <th>sql</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>table</td>\n",
       "      <td>by</td>\n",
       "      <td>by</td>\n",
       "      <td>2</td>\n",
       "      <td>CREATE TABLE \"by\" (\\n\\t\"index\" BIGINT, \\n\\tlic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>table</td>\n",
       "      <td>by-sa</td>\n",
       "      <td>by-sa</td>\n",
       "      <td>28</td>\n",
       "      <td>CREATE TABLE \"by-sa\" (\\n\\t\"index\" BIGINT, \\n\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>table</td>\n",
       "      <td>by-nc</td>\n",
       "      <td>by-nc</td>\n",
       "      <td>410</td>\n",
       "      <td>CREATE TABLE \"by-nc\" (\\n\\t\"index\" BIGINT, \\n\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>table</td>\n",
       "      <td>by-nc-sa</td>\n",
       "      <td>by-nc-sa</td>\n",
       "      <td>436</td>\n",
       "      <td>CREATE TABLE \"by-nc-sa\" (\\n\\t\"index\" BIGINT, \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>table</td>\n",
       "      <td>by-nd</td>\n",
       "      <td>by-nd</td>\n",
       "      <td>1223</td>\n",
       "      <td>CREATE TABLE \"by-nd\" (\\n\\t\"index\" BIGINT, \\n\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>table</td>\n",
       "      <td>by-nc-nd</td>\n",
       "      <td>by-nc-nd</td>\n",
       "      <td>1590</td>\n",
       "      <td>CREATE TABLE \"by-nc-nd\" (\\n\\t\"index\" BIGINT, \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>table</td>\n",
       "      <td>publicdomain</td>\n",
       "      <td>publicdomain</td>\n",
       "      <td>803</td>\n",
       "      <td>CREATE TABLE publicdomain (\\n\\t\"index\" BIGINT,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    type          name      tbl_name  rootpage  \\\n",
       "0  table            by            by         2   \n",
       "1  table         by-sa         by-sa        28   \n",
       "2  table         by-nc         by-nc       410   \n",
       "3  table      by-nc-sa      by-nc-sa       436   \n",
       "4  table         by-nd         by-nd      1223   \n",
       "5  table      by-nc-nd      by-nc-nd      1590   \n",
       "6  table  publicdomain  publicdomain       803   \n",
       "\n",
       "                                                 sql  \n",
       "0  CREATE TABLE \"by\" (\\n\\t\"index\" BIGINT, \\n\\tlic...  \n",
       "1  CREATE TABLE \"by-sa\" (\\n\\t\"index\" BIGINT, \\n\\t...  \n",
       "2  CREATE TABLE \"by-nc\" (\\n\\t\"index\" BIGINT, \\n\\t...  \n",
       "3  CREATE TABLE \"by-nc-sa\" (\\n\\t\"index\" BIGINT, \\...  \n",
       "4  CREATE TABLE \"by-nd\" (\\n\\t\"index\" BIGINT, \\n\\t...  \n",
       "5  CREATE TABLE \"by-nc-nd\" (\\n\\t\"index\" BIGINT, \\...  \n",
       "6  CREATE TABLE publicdomain (\\n\\t\"index\" BIGINT,...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables = pd.read_sql(\"SELECT * FROM sqlite_master WHERE type = 'table'\", dataset_engine)\n",
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>license</th>\n",
       "      <th>url</th>\n",
       "      <th>contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5727</th>\n",
       "      <td>publicdomain/mark/1.0</td>\n",
       "      <td>https://mdsoar.org/handle/11603/22108</td>\n",
       "      <td>Progress on Ultra-Heavy Cosmic-Ray Analysis wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4402</th>\n",
       "      <td>licenses/by-nd/3.0</td>\n",
       "      <td>https://interagencystandingcommittee.org/iasc-...</td>\n",
       "      <td>My Hero is You, Storybook for Children on COVI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2672</th>\n",
       "      <td>licenses/by-nc/3.0</td>\n",
       "      <td>https://www.britishmuseum.org/terms-use/copyri...</td>\n",
       "      <td>405 Not allowed Error 405 Not allowed Not allo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5693</th>\n",
       "      <td>publicdomain/zero/1.0</td>\n",
       "      <td>https://copyright.unimelb.edu.au/guides/findin...</td>\n",
       "      <td>Searching Google for Creative Commons images S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4005</th>\n",
       "      <td>licenses/by-nd/4.0</td>\n",
       "      <td>https://www.loc.gov/marc/bibliographic/bd540.html</td>\n",
       "      <td>MARC 21 Format for Bibliographic Data: 540:\\n ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    license  \\\n",
       "5727  publicdomain/mark/1.0   \n",
       "4402     licenses/by-nd/3.0   \n",
       "2672     licenses/by-nc/3.0   \n",
       "5693  publicdomain/zero/1.0   \n",
       "4005     licenses/by-nd/4.0   \n",
       "\n",
       "                                                    url  \\\n",
       "5727              https://mdsoar.org/handle/11603/22108   \n",
       "4402  https://interagencystandingcommittee.org/iasc-...   \n",
       "2672  https://www.britishmuseum.org/terms-use/copyri...   \n",
       "5693  https://copyright.unimelb.edu.au/guides/findin...   \n",
       "4005  https://www.loc.gov/marc/bibliographic/bd540.html   \n",
       "\n",
       "                                               contents  \n",
       "5727  Progress on Ultra-Heavy Cosmic-Ray Analysis wi...  \n",
       "4402  My Hero is You, Storybook for Children on COVI...  \n",
       "2672  405 Not allowed Error 405 Not allowed Not allo...  \n",
       "5693  Searching Google for Creative Commons images S...  \n",
       "4005  MARC 21 Format for Bibliographic Data: 540:\\n ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webpages_dataset = pd.concat(\n",
    "    [\n",
    "        pd.read_sql(f\"SELECT * FROM '{table_name}'\", dataset_engine)\n",
    "        for table_name in tables[\"name\"]\n",
    "    ]\n",
    ")\n",
    "webpages_dataset = webpages_dataset\\\n",
    "    .loc[webpages_dataset[\"contents\"] != \"\", :]\\\n",
    "    .reset_index()\\\n",
    "    .drop([\"index\", \"title\", \"level_0\"], axis=1)\n",
    "webpages_dataset.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>license</th>\n",
       "      <th>contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1844</td>\n",
       "      <td>1844</td>\n",
       "      <td>1844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1844</td>\n",
       "      <td>39</td>\n",
       "      <td>1788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>http://agroportal.lirmm.fr/ontologies/PCO</td>\n",
       "      <td>licenses/by/2.1</td>\n",
       "      <td>403 Forbidden 403 Forbidden nginx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              url          license  \\\n",
       "count                                        1844             1844   \n",
       "unique                                       1844               39   \n",
       "top     http://agroportal.lirmm.fr/ontologies/PCO  licenses/by/2.1   \n",
       "freq                                            1              130   \n",
       "\n",
       "                                 contents  \n",
       "count                                1844  \n",
       "unique                               1788  \n",
       "top     403 Forbidden 403 Forbidden nginx  \n",
       "freq                                   25  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webpages_dataset_deduplicate = webpages_dataset.groupby(\"url\").first()\\\n",
    "    .reset_index()\n",
    "webpages_dataset_deduplicate.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>license</th>\n",
       "      <th>Tool Typing</th>\n",
       "      <th>General Typing</th>\n",
       "      <th>Version</th>\n",
       "      <th>by</th>\n",
       "      <th>sa</th>\n",
       "      <th>nc</th>\n",
       "      <th>nd</th>\n",
       "      <th>neither</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>licenses/by/1.0</td>\n",
       "      <td>licenses</td>\n",
       "      <td>by</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>licenses/by/2.0</td>\n",
       "      <td>licenses</td>\n",
       "      <td>by</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>licenses/by/2.1</td>\n",
       "      <td>licenses</td>\n",
       "      <td>by</td>\n",
       "      <td>2.1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>licenses/by/2.5</td>\n",
       "      <td>licenses</td>\n",
       "      <td>by</td>\n",
       "      <td>2.5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>licenses/by/3.0</td>\n",
       "      <td>licenses</td>\n",
       "      <td>by</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>licenses/by/4.0</td>\n",
       "      <td>licenses</td>\n",
       "      <td>by</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            license Tool Typing General Typing  Version    by     sa     nc  \\\n",
       "0   licenses/by/1.0    licenses             by      1.0  True  False  False   \n",
       "14  licenses/by/2.0    licenses             by      2.0  True  False  False   \n",
       "27  licenses/by/2.1    licenses             by      2.1  True  False  False   \n",
       "33  licenses/by/2.5    licenses             by      2.5  True  False  False   \n",
       "39  licenses/by/3.0    licenses             by      3.0  True  False  False   \n",
       "45  licenses/by/4.0    licenses             by      4.0  True  False  False   \n",
       "\n",
       "       nd  neither  \n",
       "0   False    False  \n",
       "14  False    False  \n",
       "27  False    False  \n",
       "33  False    False  \n",
       "39  False    False  \n",
       "45  False    False  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dataset_sampling\n",
    "license_map = dataset_sampling.get_license_map()\n",
    "license_ser = pd.concat([v for v in license_map.values()])\n",
    "license_ser_splits_df = license_ser.str.split(\"/\", expand=True)\n",
    "license_ser_splits_df = license_ser_splits_df.rename(\n",
    "    columns = {\n",
    "        0: \"Tool Typing\",\n",
    "        1: \"General Typing\",\n",
    "        2: \"Version\",\n",
    "        3: \"Jurisdiction\"\n",
    "    }\n",
    ")\n",
    "license_ser_splits_df[\"General Typing\"] = license_ser_splits_df[\"General Typing\"].str.replace(\"mark|zero\", \"publicdomain\", regex=True)\n",
    "license_ser_splits_df[\"General Typing\"] = license_ser_splits_df[\"General Typing\"].str.replace(\"by-nd-nc\", \"by-nc-nd\", regex=True)\n",
    "license_ser_splits_df[\"Version\"] = license_ser_splits_df[\"Version\"].astype(float)\n",
    "license_one_hot_encoding = pd.DataFrame()\n",
    "license_one_hot_encoding[\"by\"] = license_ser_splits_df[\"General Typing\"].str.contains(\"by\")\n",
    "license_one_hot_encoding[\"sa\"] = license_ser_splits_df[\"General Typing\"].str.contains(\"sa\")\n",
    "license_one_hot_encoding[\"nc\"] = license_ser_splits_df[\"General Typing\"].str.contains(\"nc\")\n",
    "license_one_hot_encoding[\"nd\"] = license_ser_splits_df[\"General Typing\"].str.contains(\"nd\")\n",
    "license_not_six_type = license_ser_splits_df[\"General Typing\"].str.contains(\"by|sa|nc|nd\")\n",
    "license_one_hot_encoding[\"neither\"] = ~(license_not_six_type.fillna(False))\n",
    "license_df = pd.concat([license_ser, license_ser_splits_df, license_one_hot_encoding], axis = 1)\\\n",
    "    .rename(columns = {0: \"license\"})\n",
    "license_df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>license</th>\n",
       "      <th>contents</th>\n",
       "      <th>Tool Typing</th>\n",
       "      <th>General Typing</th>\n",
       "      <th>Version</th>\n",
       "      <th>by</th>\n",
       "      <th>sa</th>\n",
       "      <th>nc</th>\n",
       "      <th>nd</th>\n",
       "      <th>neither</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>https://www.nature.com/articles/s43705-021-000...</td>\n",
       "      <td>licenses/by/2.0</td>\n",
       "      <td>iVirus 2.0: Cyberinfrastructure-supported tool...</td>\n",
       "      <td>licenses</td>\n",
       "      <td>by</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
<<<<<<< HEAD
       "      <th>725</th>\n",
       "      <td>https://collections.lib.utah.edu/ark:/87278/s6...</td>\n",
       "      <td>licenses/by-nc-sa/2.5</td>\n",
       "      <td>PediNeuroLogic Exam: Newborn: Normal: Tone - A...</td>\n",
       "      <td>licenses</td>\n",
       "      <td>by-nc-sa</td>\n",
       "      <td>2.5</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>https://podcasts.apple.com/us/podcast/cast-of-...</td>\n",
       "      <td>licenses/by/1.0</td>\n",
       "      <td>‎Cast of Many Things on Apple Podcasts Global ...</td>\n",
       "      <td>licenses</td>\n",
       "      <td>by</td>\n",
       "      <td>1.0</td>\n",
<<<<<<< HEAD
=======
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>https://www.khronos.org/opencl/assets/CXX_for_...</td>\n",
       "      <td>licenses/by/1.0</td>\n",
       "      <td>The C++ for OpenCL 1.0 and 2021 Programming La...</td>\n",
       "      <td>licenses</td>\n",
       "      <td>by</td>\n",
       "      <td>1.0</td>\n",
>>>>>>> parent of eeb1f9e (current wip at 48, 70, 78)
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>https://www.khronos.org/opencl/assets/CXX_for_...</td>\n",
       "      <td>licenses/by/1.0</td>\n",
       "      <td>The C++ for OpenCL 1.0 and 2021 Programming La...</td>\n",
       "      <td>licenses</td>\n",
       "      <td>by</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
=======
       "      <th>268</th>\n",
       "      <td>https://github.com/readium/webpub-manifest/iss...</td>\n",
       "      <td>licenses/by/3.0</td>\n",
       "      <td>Metadata links (EPUB parsing) · Issue #28 · re...</td>\n",
       "      <td>licenses</td>\n",
       "      <td>by</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
>>>>>>> parent of 458e717 (intermediate progress on failing dataset)
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1490</th>\n",
       "      <td>https://sketchfab.com/blogs/community/an-intro...</td>\n",
       "      <td>licenses/by-sa/3.0</td>\n",
       "      <td>An Introduction to Creative Commons Licenses -...</td>\n",
       "      <td>licenses</td>\n",
       "      <td>by-sa</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>https://intelligence.weforum.org/terms-and-con...</td>\n",
       "      <td>licenses/by-nd/4.0</td>\n",
       "      <td>Strategic Intelligence You need to enable Java...</td>\n",
       "      <td>licenses</td>\n",
       "      <td>by-nd</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>https://fontawesome.com/license</td>\n",
       "      <td>licenses/by/4.0</td>\n",
       "      <td>Pro License | Font Awesome</td>\n",
       "      <td>licenses</td>\n",
       "      <td>by</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
       "                                                   url                license  \\\n",
       "485  https://tsammalex.clld.org/parameters/psidiumg...  publicdomain/mark/1.0   \n",
       "977  https://www.thomsontreks.com/blog/kilimanjaro-...     licenses/by-sa/2.5   \n",
       "725  https://collections.lib.utah.edu/ark:/87278/s6...  licenses/by-nc-sa/2.5   \n",
       "815  https://podcasts.apple.com/us/podcast/cast-of-...        licenses/by/1.0   \n",
       "845  https://www.khronos.org/opencl/assets/CXX_for_...        licenses/by/1.0   \n",
       "\n",
       "                                              contents   Tool Typing  \\\n",
       "485  Tsammalex -\\n            Psidium guajava (guav...  publicdomain   \n",
       "977                  403 Forbidden 403 Forbidden nginx      licenses   \n",
       "725  PediNeuroLogic Exam: Newborn: Normal: Tone - A...      licenses   \n",
       "815  ‎Cast of Many Things on Apple Podcasts Global ...      licenses   \n",
       "845  The C++ for OpenCL 1.0 and 2021 Programming La...      licenses   \n",
       "\n",
       "    General Typing  Version     by     sa     nc     nd  neither  \n",
       "485   publicdomain      1.0  False  False  False  False     True  \n",
       "977          by-sa      2.5   True   True  False  False    False  \n",
       "725       by-nc-sa      2.5   True   True   True  False    False  \n",
       "815             by      1.0   True  False  False  False    False  \n",
       "845             by      1.0   True  False  False  False    False  "
      ]
     },
     "execution_count": 183,
=======
       "                                                    url             license  \\\n",
       "1246  https://www.nature.com/articles/s43705-021-000...     licenses/by/2.0   \n",
       "268   https://github.com/readium/webpub-manifest/iss...     licenses/by/3.0   \n",
       "1490  https://sketchfab.com/blogs/community/an-intro...  licenses/by-sa/3.0   \n",
       "1695  https://intelligence.weforum.org/terms-and-con...  licenses/by-nd/4.0   \n",
       "129                     https://fontawesome.com/license     licenses/by/4.0   \n",
       "\n",
       "                                               contents Tool Typing  \\\n",
       "1246  iVirus 2.0: Cyberinfrastructure-supported tool...    licenses   \n",
       "268   Metadata links (EPUB parsing) · Issue #28 · re...    licenses   \n",
       "1490  An Introduction to Creative Commons Licenses -...    licenses   \n",
       "1695  Strategic Intelligence You need to enable Java...    licenses   \n",
       "129                          Pro License | Font Awesome    licenses   \n",
       "\n",
       "     General Typing  Version    by     sa     nc     nd  neither  \n",
       "1246             by      2.0  True  False  False  False    False  \n",
       "268              by      3.0  True  False  False  False    False  \n",
       "1490          by-sa      3.0  True   True  False  False    False  \n",
       "1695          by-nd      4.0  True  False  False   True    False  \n",
       "129              by      4.0  True  False  False  False    False  "
      ]
     },
     "execution_count": 7,
>>>>>>> parent of 458e717 (intermediate progress on failing dataset)
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webpages_dataset_deduplicate = webpages_dataset_deduplicate.merge(license_df, on = \"license\")\n",
    "webpages_dataset_deduplicate.sample(5)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 184,
=======
   "execution_count": 8,
>>>>>>> parent of 458e717 (intermediate progress on failing dataset)
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>license</th>\n",
       "      <th>contents</th>\n",
       "      <th>Tool Typing</th>\n",
       "      <th>Version</th>\n",
       "      <th>by</th>\n",
       "      <th>sa</th>\n",
       "      <th>nc</th>\n",
       "      <th>nd</th>\n",
       "      <th>neither</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>General Typing</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>by</th>\n",
<<<<<<< HEAD
       "      <td>402</td>\n",
       "      <td>402</td>\n",
       "      <td>402</td>\n",
       "      <td>402</td>\n",
       "      <td>402</td>\n",
       "      <td>402</td>\n",
       "      <td>402</td>\n",
       "      <td>402</td>\n",
       "      <td>402</td>\n",
       "      <td>402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>by-nc</th>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>by-nc-nd</th>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>by-nc-sa</th>\n",
       "      <td>175</td>\n",
       "      <td>175</td>\n",
       "      <td>175</td>\n",
       "      <td>175</td>\n",
       "      <td>175</td>\n",
       "      <td>175</td>\n",
       "      <td>175</td>\n",
       "      <td>175</td>\n",
       "      <td>175</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>by-nd</th>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>by-sa</th>\n",
       "      <td>237</td>\n",
       "      <td>237</td>\n",
       "      <td>237</td>\n",
       "      <td>237</td>\n",
       "      <td>237</td>\n",
       "      <td>237</td>\n",
       "      <td>237</td>\n",
       "      <td>237</td>\n",
       "      <td>237</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publicdomain</th>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
=======
       "      <td>720</td>\n",
       "      <td>720</td>\n",
       "      <td>720</td>\n",
       "      <td>720</td>\n",
       "      <td>720</td>\n",
       "      <td>720</td>\n",
       "      <td>720</td>\n",
       "      <td>720</td>\n",
       "      <td>720</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>by-nc</th>\n",
       "      <td>225</td>\n",
       "      <td>225</td>\n",
       "      <td>225</td>\n",
       "      <td>225</td>\n",
       "      <td>225</td>\n",
       "      <td>225</td>\n",
       "      <td>225</td>\n",
       "      <td>225</td>\n",
       "      <td>225</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>by-nc-nd</th>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>by-nc-sa</th>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>by-nd</th>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>by-sa</th>\n",
       "      <td>263</td>\n",
       "      <td>263</td>\n",
       "      <td>263</td>\n",
       "      <td>263</td>\n",
       "      <td>263</td>\n",
       "      <td>263</td>\n",
       "      <td>263</td>\n",
       "      <td>263</td>\n",
       "      <td>263</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publicdomain</th>\n",
       "      <td>224</td>\n",
       "      <td>224</td>\n",
       "      <td>224</td>\n",
       "      <td>224</td>\n",
       "      <td>224</td>\n",
       "      <td>224</td>\n",
       "      <td>224</td>\n",
       "      <td>224</td>\n",
       "      <td>224</td>\n",
       "      <td>224</td>\n",
>>>>>>> parent of 458e717 (intermediate progress on failing dataset)
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                url  license  contents  Tool Typing  Version   by   sa   nc  \\\n",
       "General Typing                                                                \n",
<<<<<<< HEAD
       "by              402      402       402          402      402  402  402  402   \n",
       "by-nc           216      216       216          216      216  216  216  216   \n",
       "by-nc-nd         99       99        99           99       99   99   99   99   \n",
       "by-nc-sa        175      175       175          175      175  175  175  175   \n",
       "by-nd           113      113       113          113      113  113  113  113   \n",
       "by-sa           237      237       237          237      237  237  237  237   \n",
       "publicdomain    149      149       149          149      149  149  149  149   \n",
       "\n",
       "                 nd  neither  \n",
       "General Typing                \n",
       "by              402      402  \n",
       "by-nc           216      216  \n",
       "by-nc-nd         99       99  \n",
       "by-nc-sa        175      175  \n",
       "by-nd           113      113  \n",
       "by-sa           237      237  \n",
       "publicdomain    149      149  "
      ]
     },
     "execution_count": 184,
=======
       "by              720      720       720          720      720  720  720  720   \n",
       "by-nc           225      225       225          225      225  225  225  225   \n",
       "by-nc-nd        107      107       107          107      107  107  107  107   \n",
       "by-nc-sa        188      188       188          188      188  188  188  188   \n",
       "by-nd           117      117       117          117      117  117  117  117   \n",
       "by-sa           263      263       263          263      263  263  263  263   \n",
       "publicdomain    224      224       224          224      224  224  224  224   \n",
       "\n",
       "                 nd  neither  \n",
       "General Typing                \n",
       "by              720      720  \n",
       "by-nc           225      225  \n",
       "by-nc-nd        107      107  \n",
       "by-nc-sa        188      188  \n",
       "by-nd           117      117  \n",
       "by-sa           263      263  \n",
       "publicdomain    224      224  "
      ]
     },
     "execution_count": 8,
>>>>>>> parent of 458e717 (intermediate progress on failing dataset)
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webpages_dataset_deduplicate.groupby(\"General Typing\").count()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 185,
=======
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#webpages_dataset_deduplicate[\"contents\"] = webpages_dataset_deduplicate[\"contents\"].apply(lambda x: x[:3500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
>>>>>>> parent of 458e717 (intermediate progress on failing dataset)
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def remove_unicodes(ser):\n",
<<<<<<< HEAD
    "    return ser.map(lambda x: \"\".join([c for c in x if c in string.printable]))"
=======
    "    return ser.map(lambda x: \"\".join([c for c in x if c in string.printable]))\n",
    "\n",
    "def has_unicodes(s, tolerance = 25):\n",
    "    return np.sum([c not in string.printable for c in s]) <= tolerance\n",
    "\n",
    "def not_well_decrypted(s, tolerance = 25):\n",
    "    words = re.split(r\"\\s+\", s)\n",
    "    return np.sum([len(c) == 1 for c in words]) <= tolerance\n",
    "\n",
    "def remove_unicodes_aggressive(df, field_name = \"contents\"):\n",
    "    df_remove_unicode = df.loc[df[field_name].apply(has_unicodes), :]\n",
    "    df_remove_unicode = df_remove_unicode.loc[\n",
    "        df_remove_unicode[field_name].str.len() >= 500, :\n",
    "    ]\n",
    "    return df_remove_unicode"
>>>>>>> parent of 458e717 (intermediate progress on failing dataset)
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 186,
=======
   "execution_count": 11,
>>>>>>> parent of 458e717 (intermediate progress on failing dataset)
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "contents           FALQs: Execution of Drug Offenders in Indonesi...\n",
       "parsed_contents    FALQs: Execution of Drug Offenders in Indonesi...\n",
       "Name: 1149, dtype: object"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "webpages_dataset_deduplicate[\"parsed_contents\"] = remove_unicodes(webpages_dataset_deduplicate[\"contents\"])\n",
    "webpages_dataset_deduplicate.loc[1149, [\"contents\", \"parsed_contents\"]]"
=======
    "# Less Aggressive pruning\n",
    "#webpages_dataset_deduplicate[\"parsed_contents\"] = remove_unicodes(webpages_dataset_deduplicate[\"contents\"])\n",
    "#webpages_dataset_deduplicate.loc[1149, [\"contents\", \"parsed_contents\"]]\n",
    "\n",
    "# More Aggressive pruning\n",
    "webpages_dataset_deduplicate = remove_unicodes_aggressive(webpages_dataset_deduplicate)"
>>>>>>> parent of 458e717 (intermediate progress on failing dataset)
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "webpages_dataset_deduplicate[\"parsed_contents\"] = \\\n",
    "    webpages_dataset_deduplicate[\"parsed_contents\"].str.replace(\n",
    "        r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|(^rt)|(http.+?)|(www.+?)|(\\d{3}\\s*\\w+\\b)|([\\n\\t])|(\\d)\",\n",
    "        \" \",\n",
    "        regex = True\n",
    "    )"
=======
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_less_than_c_chars(s, tolerance = 1):\n",
    "    words = re.split(r\"\\s+\", s)\n",
    "    return \" \".join([c for c in words if len(c) > tolerance and \"obj\" not in c])\n",
    "\n",
    "def remove_more_than_c_chars(s, tolerance = 15):\n",
    "    words = re.split(r\"\\s+\", s)\n",
    "    return \" \".join([c for c in words if len(c) <= tolerance])\n",
    "\n",
    "def remove_non_english(s):\n",
    "    words = set(nltk.corpus.words.words())\n",
    "    return \" \".join(w for w in re.split(r\"\\s+\", s) if w in words)\n",
    "\n",
    "def remove_web_urls(s):\n",
    "    return re.sub(r\"[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)\", \" \", s)\n",
    "\n",
    "def overall_cleaning(ser):\n",
    "    cleaned_ser = ser.str.lower()\n",
    "    cleaned_ser = cleaned_ser.apply(\n",
    "        lambda s: \" \".join([word for word in re.split(r\"\\s+\", s) if word.lower() not in nltk.corpus.stopwords.words('english')])\n",
    "    )\n",
    "    cleaned_ser = cleaned_ser.str.replace(r'[^\\w\\s]', ' ', regex = True)\n",
    "    #cleaned_ser = cleaned_ser.str.replace(r\"\\s+\", \" \", regex = True)\n",
    "    cleaned_ser = cleaned_ser.apply(remove_less_than_c_chars)\n",
    "    #cleaned_ser = cleaned_ser.apply(remove_non_english)\n",
    "    cleaned_ser = cleaned_ser.apply(remove_more_than_c_chars)\n",
    "    return cleaned_ser\n",
    "\n",
    "webpages_dataset_deduplicate[\"parsed_cleaned_contents\"] = overall_cleaning(webpages_dataset_deduplicate[\"contents\"])\n"
>>>>>>> parent of 458e717 (intermediate progress on failing dataset)
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
<<<<<<< HEAD
=======
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry content:\n",
      "cavalry crossing temporary bridge flickr world war centenary open educational resource supporting new directions teaching world war find skip content home themes resource library contributors places contact us login cavalry crossing temporary bridge flickr categories battle arras subscribe share facebook share twitter access resource cavalry move world war line relaxed cavalrymen crossing small narrow bridge wintry landscape clearly visible two foot soldiers sit jerry cans watch cavalry pass crucifix side road re erected possibly photograph amidst bombed out landscape war broke 1914 yet tested effective alternative using cavalry war later world war tanks began introduced second world war cav\n",
      "\n",
      "Entry content:\n",
      "extended mapping cis controls iso27001 security controls identity underground identity underground connector space internet metaverse also external memory easily share learn menu publications short bio speaking engagements out of scope something different linkedin connection suggestion greatest hits cipm companion links useful gdpr resources iso27001 iso27002 downloads tools interesting links eid be reference material cybersecurity reference material ethical hacking useful resources curation gdpr reference material microsoft identity reference pages useful cybersecurity data protection breach reports references public ransomware cybercrime databreaches for educational purposes note to self r\n",
      "\n",
      "Entry content:\n",
      "antique patterns available free antique pattern library menu close home enfys crochet work classes events weekly classes saturday workshops links treble trouble rainbow valley cal patterns english häkelmuster deutsch virkmönster svenska craft supplies kits flora klickman antique books basic stitches crochet techniques reading patterns learn crotat tunisian crochet chatteris pages constantly updated please make sure refresh get latest version terms conditions privacy policy contact opening hours like antique patterns love antique pattern library information library https groups yahoo com group join receive emails add new books links library also information group site donating book scans volu\n",
      "\n",
      "Entry content:\n",
      "channeling passions developing successful social media strategy elizabeth ramsey amy vecchione home search browse collections account digital commons network skip main content scholarworks home faq account previous next home library library publications 101 library faculty publications presentations title channeling passions developing successful social media strategy authors elizabeth ramsey boise state university follow amy vecchione boise state university follow document type article publication date 2014 abstract libraries often struggle developing consistent message communicates relevance value patrons comes social media strategy it understood consistency essential aspect library brandi\n",
      "\n",
      "Entry content:\n",
      "digital identifier system home handbook factsheets faqs resources registration agencies news members area doi system iso 26324 web site international doi foundation idf not for profit membership organization governance management body federation registration agencies providing digital identifier doi services registration registration authority iso standard iso 26324 doi system doi system provides technical social infrastructure registration use persistent interoperable identifiers called dois use digital networks resolve doi name type paste doi name 10 1000 xyz123 text box below be sure enter characters slash include extra characters sentence punctuation marks clicking doi link try one https\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for row in webpages_dataset_deduplicate[\"parsed_cleaned_contents\"].sample(5):\n",
    "    print(\n",
    "        f\"Entry content:\\n{row[:700]}\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import top_k_accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
>>>>>>> parent of 458e717 (intermediate progress on failing dataset)
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contents</th>\n",
       "      <th>parsed_contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>DADUN: Associations between olfactory pathway ...</td>\n",
       "      <td>DADUN  Associations between olfactory pathway ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>403 Forbidden 403 Forbidden Access to this res...</td>\n",
       "      <td>Access to this resource on the server is d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>The Bee’s Knees. Curious Turns of Phrase #3 | ...</td>\n",
       "      <td>The Bees Knees  Curious Turns of Phrase      b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Creative Commons Attribution 3.0 Unported (CC ...</td>\n",
       "      <td>Creative Commons Attribution     Unported  CC ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>Branch Retinal Vein Occlusion - EyeWiki Create...</td>\n",
       "      <td>Branch Retinal Vein Occlusion   EyeWiki Create...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>Some marijuana is being laced with meth and fe...</td>\n",
       "      <td>Some marijuana is being laced with meth and fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>An Osmosis Video: Congestive Heart Failure (CH...</td>\n",
       "      <td>An Osmosis Video  Congestive Heart Failure  CH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>\"Household ecology and out-migration among eth...</td>\n",
       "      <td>Household ecology and out migration among eth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>🎈 Public Lab: bioassay Lead image: Sprouting l...</td>\n",
       "      <td>Public Lab  bioassay Lead image  Sprouting le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>403 Forbidden 403 Forbidden nginx</td>\n",
       "      <td>nginx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               contents  \\\n",
       "453   DADUN: Associations between olfactory pathway ...   \n",
       "1108  403 Forbidden 403 Forbidden Access to this res...   \n",
       "886   The Bee’s Knees. Curious Turns of Phrase #3 | ...   \n",
       "48    Creative Commons Attribution 3.0 Unported (CC ...   \n",
       "646   Branch Retinal Vein Occlusion - EyeWiki Create...   \n",
       "504   Some marijuana is being laced with meth and fe...   \n",
       "438   An Osmosis Video: Congestive Heart Failure (CH...   \n",
       "536   \"Household ecology and out-migration among eth...   \n",
       "991   🎈 Public Lab: bioassay Lead image: Sprouting l...   \n",
       "1147                  403 Forbidden 403 Forbidden nginx   \n",
       "\n",
       "                                        parsed_contents  \n",
       "453   DADUN  Associations between olfactory pathway ...  \n",
       "1108      Access to this resource on the server is d...  \n",
       "886   The Bees Knees  Curious Turns of Phrase      b...  \n",
       "48    Creative Commons Attribution     Unported  CC ...  \n",
       "646   Branch Retinal Vein Occlusion   EyeWiki Create...  \n",
       "504   Some marijuana is being laced with meth and fe...  \n",
       "438   An Osmosis Video  Congestive Heart Failure  CH...  \n",
       "536    Household ecology and out migration among eth...  \n",
       "991    Public Lab  bioassay Lead image  Sprouting le...  \n",
       "1147                                              nginx  "
      ]
     },
<<<<<<< HEAD
     "execution_count": 213,
=======
     "execution_count": 15,
>>>>>>> parent of 458e717 (intermediate progress on failing dataset)
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "webpages_dataset_deduplicate[[\"contents\", \"parsed_contents\"]].sample(10)"
=======
    "def tokenize_url(url):\n",
    "    return \" \".join(re.split(r\"[_/\\.-]\", re.sub(r\"\\d\", \"\", url)))\n",
    "tokenize_url(\"creativecommons.org/licenses/by-sa/4.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>license</th>\n",
       "      <th>contents</th>\n",
       "      <th>Tool Typing</th>\n",
       "      <th>General Typing</th>\n",
       "      <th>Version</th>\n",
       "      <th>by</th>\n",
       "      <th>sa</th>\n",
       "      <th>nc</th>\n",
       "      <th>nd</th>\n",
       "      <th>neither</th>\n",
       "      <th>parsed_cleaned_contents</th>\n",
       "      <th>token_url</th>\n",
       "      <th>train_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>https://www.science.org/content/page/terms-ser...</td>\n",
       "      <td>licenses/by-nc/4.0</td>\n",
       "      <td>Terms of Service | Science | AAAS Advertisemen...</td>\n",
       "      <td>licenses</td>\n",
       "      <td>by-nc</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>terms service science aaas advertisement news ...</td>\n",
       "      <td>https:  www science org content page terms ser...</td>\n",
       "      <td>https:  www science org content page terms ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>https://digital.bodleian.ox.ac.uk/terms/</td>\n",
       "      <td>licenses/by-nc/4.0</td>\n",
       "      <td>Digital Bodleian | Terms of use Search Browse ...</td>\n",
       "      <td>licenses</td>\n",
       "      <td>by-nc</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>digital bodleian terms use search browse digit...</td>\n",
       "      <td>https:  digital bodleian ox ac uk terms</td>\n",
       "      <td>https:  digital bodleian ox ac uk terms  digit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>https://scholars.cityu.edu.hk/en/publications/...</td>\n",
       "      <td>licenses/by-nc/3.0</td>\n",
       "      <td>Organocatalytic asymmetric formal oxidative co...</td>\n",
       "      <td>licenses</td>\n",
       "      <td>by-nc</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>organocatalytic asymmetric formal oxidative co...</td>\n",
       "      <td>https:  scholars cityu edu hk en publications ...</td>\n",
       "      <td>https:  scholars cityu edu hk en publications ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>https://starwars.fandom.com/wiki/Wookieepedia:...</td>\n",
       "      <td>licenses/by-sa/2.1</td>\n",
       "      <td>Wookieepedia:Copyrights | Wookieepedia | Fando...</td>\n",
       "      <td>licenses</td>\n",
       "      <td>by-sa</td>\n",
       "      <td>2.1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>wookieepedia copyrights wookieepedia fandom wo...</td>\n",
       "      <td>https:  starwars fandom com wiki Wookieepedia:...</td>\n",
       "      <td>https:  starwars fandom com wiki Wookieepedia:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>https://trade4devnews.enhancedif.org/en/impact...</td>\n",
       "      <td>licenses/by-nc-nd/2.0</td>\n",
       "      <td>How to engage businesses in international deve...</td>\n",
       "      <td>licenses</td>\n",
       "      <td>by-nc-nd</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>engage businesses international development tr...</td>\n",
       "      <td>https:  tradedevnews enhancedif org en impact ...</td>\n",
       "      <td>https:  tradedevnews enhancedif org en impact ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    url  \\\n",
       "512   https://www.science.org/content/page/terms-ser...   \n",
       "465            https://digital.bodleian.ox.ac.uk/terms/   \n",
       "763   https://scholars.cityu.edu.hk/en/publications/...   \n",
       "424   https://starwars.fandom.com/wiki/Wookieepedia:...   \n",
       "1636  https://trade4devnews.enhancedif.org/en/impact...   \n",
       "\n",
       "                    license  \\\n",
       "512      licenses/by-nc/4.0   \n",
       "465      licenses/by-nc/4.0   \n",
       "763      licenses/by-nc/3.0   \n",
       "424      licenses/by-sa/2.1   \n",
       "1636  licenses/by-nc-nd/2.0   \n",
       "\n",
       "                                               contents Tool Typing  \\\n",
       "512   Terms of Service | Science | AAAS Advertisemen...    licenses   \n",
       "465   Digital Bodleian | Terms of use Search Browse ...    licenses   \n",
       "763   Organocatalytic asymmetric formal oxidative co...    licenses   \n",
       "424   Wookieepedia:Copyrights | Wookieepedia | Fando...    licenses   \n",
       "1636  How to engage businesses in international deve...    licenses   \n",
       "\n",
       "     General Typing  Version    by     sa     nc     nd  neither  \\\n",
       "512           by-nc      4.0  True  False   True  False    False   \n",
       "465           by-nc      4.0  True  False   True  False    False   \n",
       "763           by-nc      3.0  True  False   True  False    False   \n",
       "424           by-sa      2.1  True   True  False  False    False   \n",
       "1636       by-nc-nd      2.0  True  False   True   True    False   \n",
       "\n",
       "                                parsed_cleaned_contents  \\\n",
       "512   terms service science aaas advertisement news ...   \n",
       "465   digital bodleian terms use search browse digit...   \n",
       "763   organocatalytic asymmetric formal oxidative co...   \n",
       "424   wookieepedia copyrights wookieepedia fandom wo...   \n",
       "1636  engage businesses international development tr...   \n",
       "\n",
       "                                              token_url  \\\n",
       "512   https:  www science org content page terms ser...   \n",
       "465            https:  digital bodleian ox ac uk terms    \n",
       "763   https:  scholars cityu edu hk en publications ...   \n",
       "424   https:  starwars fandom com wiki Wookieepedia:...   \n",
       "1636  https:  tradedevnews enhancedif org en impact ...   \n",
       "\n",
       "                                             train_text  \n",
       "512   https:  www science org content page terms ser...  \n",
       "465   https:  digital bodleian ox ac uk terms  digit...  \n",
       "763   https:  scholars cityu edu hk en publications ...  \n",
       "424   https:  starwars fandom com wiki Wookieepedia:...  \n",
       "1636  https:  tradedevnews enhancedif org en impact ...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = webpages_dataset_deduplicate.copy()\n",
    "dataset['token_url'] = dataset[\"url\"].apply(tokenize_url)\n",
    "dataset[\"train_text\"] = dataset[\"token_url\"] + \" \" + dataset[\"parsed_cleaned_contents\"]\n",
    "dataset.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_features_tfidf(train, test, text_field = \"train_text\"):\n",
    "    tfidf_vectorizer = TfidfVectorizer(use_idf=True, max_df=0.95, stop_words=\"english\")\n",
    "    tfidf_vectorizer.fit_transform(train[text_field].values)\n",
    "    train_vectorized = tfidf_vectorizer.transform(train[text_field].values)\n",
    "    test_vectorized = tfidf_vectorizer.transform(test[text_field].values)\n",
    "    return train_vectorized, test_vectorized, tfidf_vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    542\n",
       "1    174\n",
       "2     75\n",
       "3    144\n",
       "4     77\n",
       "5    174\n",
       "6    171\n",
       "Name: url, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.groupby(\"General Typing\")[[\"url\"]].count().reset_index()[\"url\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brand\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\imblearn\\utils\\_validation.py:299: UserWarning: After over-sampling, the number of samples (542) in class 0 will be larger than the number of samples in the majority class (class #0 -> 426)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_dataset = pd.DataFrame()\n",
    "dataset_counts = dataset.groupby(\"General Typing\")[[\"url\"]].count().reset_index()[\"url\"]\n",
    "smote = SMOTE(\n",
    "    sampling_strategy={k: max(dataset_counts.iloc[k], int(np.mean(dataset_counts))) for k in range(7)} #max(dataset_counts), int(dataset_counts.iloc[k] * 1.4)\n",
    ")\n",
    "license_dict = {\n",
    "        \"by\": 0,\n",
    "        \"by-nc\": 1,\n",
    "        \"by-nc-nd\": 2,\n",
    "        \"by-nc-sa\": 3,\n",
    "        \"by-nd\": 4,\n",
    "        \"by-sa\": 5,\n",
    "        \"publicdomain\": 6\n",
    "}\n",
    "\n",
    "model_dataset[\"train_text\"], model_dataset[\"General Typing\"] = dataset[\"parsed_cleaned_contents\"], dataset[\"General Typing\"]\n",
    "model_dataset[\"General Typing\"].replace(\n",
    "    license_dict,\n",
    "    inplace = True\n",
    ")\n",
    "\n",
    "training_set, test_set = train_test_split(model_dataset, test_size = 0.2)\n",
    "Y_train = training_set[\"General Typing\"].values\n",
    "Y_test = test_set[\"General Typing\"].values\n",
    "X_train, X_test, model_vecter = extract_text_features_tfidf(\n",
    "    training_set, test_set\n",
    ")\n",
    "X_train, Y_train = smote.fit_resample(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### log reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logreg = LogisticRegression(\n",
    "    verbose = 0,\n",
    "    max_iter = 1500,\n",
    "    penalty = 'l2',\n",
    "    C = 50000\n",
    ").fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9994117647058823 \n",
      " 1.0 \n",
      " 1.0 \n",
      "==============\n",
      " 0.48161764705882354 \n",
      " 0.7169117647058824 \n",
      " 0.7977941176470589\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    top_k_accuracy_score(Y_train, model_logreg.predict_proba(X_train), k = 1),\n",
    "    \"\\n\",\n",
    "    top_k_accuracy_score(Y_train, model_logreg.predict_proba(X_train), k = 2),\n",
    "    \"\\n\",\n",
    "    top_k_accuracy_score(Y_train, model_logreg.predict_proba(X_train), k = 3),\n",
    "    \"\\n==============\\n\",\n",
    "    top_k_accuracy_score(Y_test, model_logreg.predict_proba(X_test), k = 1),\n",
    "    \"\\n\",\n",
    "    top_k_accuracy_score(Y_test, model_logreg.predict_proba(X_test), k = 2),\n",
    "    \"\\n\",\n",
    "    top_k_accuracy_score(Y_test, model_logreg.predict_proba(X_test), k = 3)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    }
   ],
   "source": [
    "model_svc = SVC(\n",
    "    C = 100000,\n",
    "    verbose = 1,\n",
    "    probability = True,\n",
    "    kernel = \"linear\"\n",
    ").fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9994117647058823 \n",
      " 1.0 \n",
      " 1.0 \n",
      "==============\n",
      " 0.4742647058823529 \n",
      " 0.6911764705882353 \n",
      " 0.7867647058823529\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    top_k_accuracy_score(Y_train, model_svc.predict_proba(X_train), k = 1),\n",
    "    \"\\n\",\n",
    "    top_k_accuracy_score(Y_train, model_svc.predict_proba(X_train), k = 2),\n",
    "    \"\\n\",\n",
    "    top_k_accuracy_score(Y_train, model_svc.predict_proba(X_train), k = 3),\n",
    "    \"\\n==============\\n\",\n",
    "    top_k_accuracy_score(Y_test, model_svc.predict_proba(X_test), k = 1),\n",
    "    \"\\n\",\n",
    "    top_k_accuracy_score(Y_test, model_svc.predict_proba(X_test), k = 2),\n",
    "    \"\\n\",\n",
    "    top_k_accuracy_score(Y_test, model_svc.predict_proba(X_test), k = 3)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from official.nlp import optimization  # to create AdamW optimizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2'\n",
    "tfhub_handle_encoder = 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1'\n",
    "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)\n",
    "bert_model = hub.KerasLayer(tfhub_handle_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "BATCH_SIZE = 8\n",
    "TRAINING_RATIO = 0.7\n",
    "\n",
    "model_dataset_copy = dataset.loc[:, [\"parsed_cleaned_contents\", \"General Typing\"]]\n",
    "model_dataset_copy[\"General Typing\"].replace(\n",
    "    license_dict,\n",
    "    inplace = True\n",
    ")\n",
    "target = model_dataset_copy.pop(\"General Typing\")\n",
    "# dataset_tensor = tf.convert_to_tensor(model_dataset, dtype=np.string_)\n",
    "tf_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((model_dataset_copy, target))\n",
    "    .shuffle(50)\n",
    ")\n",
    "train_dataset = tf_dataset.take(int(TRAINING_RATIO * len(tf_dataset)))\n",
    "test_dataset = tf_dataset.skip(int(TRAINING_RATIO * len(tf_dataset)))\n",
    "val_dataset = test_dataset.skip(\n",
    "    int((1 - TRAINING_RATIO) * 0.5 * len(tf_dataset))\n",
    ")\n",
    "test_dataset = test_dataset.take(\n",
    "    int((1 - TRAINING_RATIO) * 0.5 * len(tf_dataset))\n",
    ")\n",
    "\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier_model():\n",
    "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='parsed_cleaned_contents')\n",
    "    preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
    "    encoder_inputs = preprocessing_layer(text_input)\n",
    "    encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
    "    outputs = encoder(encoder_inputs)\n",
    "    net = outputs['pooled_output']\n",
    "    net = tf.keras.layers.Dropout(0.5)(net)\n",
    "    net = tf.keras.layers.Dense(1, activation=None, name='classifier')(net)\n",
    "    return tf.keras.Model(text_input, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_addons.metrics import F1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "steps_per_epoch = tf.data.experimental.cardinality(train_dataset).numpy()\n",
    "num_train_steps = steps_per_epoch * epochs\n",
    "num_warmup_steps = int(0.1*num_train_steps)\n",
    "\n",
    "init_lr = 1e-7\n",
    "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
    "                                          num_train_steps=num_train_steps,\n",
    "                                          num_warmup_steps=num_warmup_steps,\n",
    "                                          optimizer_type='adamw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "119/119 [==============================] - 149s 1s/step - loss: 2.6349e-07 - accuracy: 0.3155 - val_loss: 3.4658e-07 - val_accuracy: 0.0732\n",
      "Epoch 2/10\n",
      "117/119 [============================>.] - ETA: 2s - loss: 2.6427e-07 - accuracy: 0.3173"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\brand\\Desktop\\UCBF22\\DSD Fall 2022\\model_sampling\\model_dev.ipynb Cell 39\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/brand/Desktop/UCBF22/DSD%20Fall%202022/model_sampling/model_dev.ipynb#X52sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m classifier_model \u001b[39m=\u001b[39m build_classifier_model()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/brand/Desktop/UCBF22/DSD%20Fall%202022/model_sampling/model_dev.ipynb#X52sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m classifier_model\u001b[39m.\u001b[39mcompile(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/brand/Desktop/UCBF22/DSD%20Fall%202022/model_sampling/model_dev.ipynb#X52sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     optimizer\u001b[39m=\u001b[39moptimizer,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/brand/Desktop/UCBF22/DSD%20Fall%202022/model_sampling/model_dev.ipynb#X52sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/brand/Desktop/UCBF22/DSD%20Fall%202022/model_sampling/model_dev.ipynb#X52sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     metrics\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/brand/Desktop/UCBF22/DSD%20Fall%202022/model_sampling/model_dev.ipynb#X52sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m )\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/brand/Desktop/UCBF22/DSD%20Fall%202022/model_sampling/model_dev.ipynb#X52sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m history \u001b[39m=\u001b[39m classifier_model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/brand/Desktop/UCBF22/DSD%20Fall%202022/model_sampling/model_dev.ipynb#X52sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     train_dataset,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/brand/Desktop/UCBF22/DSD%20Fall%202022/model_sampling/model_dev.ipynb#X52sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     validation_data\u001b[39m=\u001b[39;49mval_dataset,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/brand/Desktop/UCBF22/DSD%20Fall%202022/model_sampling/model_dev.ipynb#X52sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/brand/Desktop/UCBF22/DSD%20Fall%202022/model_sampling/model_dev.ipynb#X52sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1378\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1379\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1380\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1381\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1382\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1383\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1384\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1385\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1386\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2953\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2954\u001b[0m   (graph_function,\n\u001b[0;32m   2955\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2957\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1849\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1850\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1851\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1852\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1853\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1854\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1855\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1856\u001b[0m     args,\n\u001b[0;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1858\u001b[0m     executing_eagerly)\n\u001b[0;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "classifier_model = build_classifier_model()\n",
    "classifier_model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "history = classifier_model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=epochs\n",
    ")"
>>>>>>> parent of 458e717 (intermediate progress on failing dataset)
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dd98d7e735064cd82a69955e27f6d0d35e8c81af503a9f702e870f7c3b7bf96a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
